# ATTEND Analysis Script: Analysis of the STNI data, for a first pass validation / psychometrics
#
# Input: "ATTEND_allOO_pulled2022-07-18.rds"
#  * Produced by: ATTEND_allOO_2022-07-18.R in HendricksonLab / Data Pull Scripts
#
# Output:
#   XXXXXX
#
# History:
#   2022-08-18 RCH wrote it

###############################
# I. Set up
###############################
```{r}
usersetting="Aaron" 
# Aaron, if you run this script and want to add default options for you that are different, just 
# swap this to "Aaron" and update away (I set up the library path portion this way as
# an example, but you may find other pLaces here that you want to swap things up a bit)

if(usersetting=="Rebecca"){
  .libPaths("C:/LocalR/R-4.0.5/library")
  githubpath="C:\\Users\\vhapughendrr\\GitHub\\"
}else if(usersetting=="Aaron"){
  # Put any library path you want to use instead here, and the path to your local github directory
  .libPaths("C:/LocalR/R-4.2.1/Library")
  githubpath="U:\\My Documents\\GitHub\\"
}else{
  warning("You'll need to set a githubpath for much of the code below to work...")
}

# Settings
importdirectories<-list(
  github=githubpath,
  workingdatasaves="R:\\MIRECC\\STUDIES\\Hendrickson_1588176-01881_ATTEND\\Study Data\\Data\\Analyses\\",
  plotsaves="R:\\MIRECC\\STUDIES\\Hendrickson_1588176-01881_ATTEND\\Study Data\\Data\\Analyses\\STNIplots\\"
)
importfilenames<-list(
  workingdata="ATTEND_allOO_pulled2022-10-27.rds"
 #Original Data File used for analysis: 
   # workingdata="ATTEND_allOO_pulled2022-7-18.rds"
 # workingdata="ATTEND BL AFR Test.rds"
)
saveoptions <- list(
  resave=TRUE,
  savetag="STNI"
)

# These you need for sure:
library(data.table)
library(ggplot2)
library(ggpubr)
library(data.table)

# I can't remember which of these you actually will need for this
library(devtools)
library(readr)
library(readxl)
library(openxlsx)
library(htmlTable)
library(rvest) # for stripping html tags
library(flextable)
library(officer)
library(nlme)
library(psych)
library(psychTools)
library(jtools) # for visualizing lm output
library(ggstance) # needed by jtools
library(broom.mixed) # needed by ggstance!
library(mediation)
library(gridExtra)
library(nlme)

# These you almost certainly won't need
library(maps)
library(ggmap)

# Just source these, because package version never up to date:
source(paste0(importdirectories$github,"HendricksonLab\\HLUtilities\\R\\Utilities.R"))
source(paste0(importdirectories$github,"HendricksonLab\\CoreInfastructure\\R\\GeneralDataFunctions.R"))
source(paste0(importdirectories$github,"HendricksonLab\\CoreInfastructure\\R\\qualtricsFunctions.R"))

# Functions:


# Plot settings that carry through:
reltextsize=1.3
labelsize=9

#################################
# II. Load the prepared data set, initial prep
#################################

dp <- readRDS(paste0(importdirectories$workingdatasaves,importfilenames$workingdata))
# dp stands for data package, which has a couple of parts:
names(dp)

# The dataQL data table is the main data:
dp$data
# You can see the column names:
names(dp$dataQL)

# Other useful one:
dp$dictionaryQL
names(dp$dictionaryQL)
# You can look at the entry for a particular variable (column in dp$dataQL):
dp$dictionaryQL[VarID=="pcl5Total"]

# Clean age:
dp$dataQL[age<21,.(age,attendDem_job)]
# the 3 that are "teens" are clearly legit responses, will change age to missing data
dp$dataQL[age<18,age:=NA]

###########################
# III. Basic characterizations
###########################

#############
# Basic demographics, profile of the responses we've gotten:

# how many responses do we have, with what completeness?
nBL <- length(dp$dataQL[VisitID=="BL"]$qaResponseID)
nFu <- length(dp$dataQL[VisitID!="BL"][trelative>0]$qaResponseID)

# Age
mAge <- mean(dp$dataQL$age,na.rm=TRUE)
sdAge <- sd(dp$dataQL$age,na.rm=TRUE)
rangeAge <- range(dp$dataQL$age,na.rm=TRUE)

# Field
nHCW <- sum(dp$dataQL[VisitID=="BL"]$attendDem_HCW)
nFR <- sum(dp$dataQL[VisitID=="BL"]$attendDem_FR)
nOverlap <- length(dp$dataQL[VisitID=="BL"][attendDem_HCW==TRUE][attendDem_FR==TRUE]$qaStartDate) # 6
nPolice <- sum(dp$dataQL[VisitID=="BL"]$attendDem_police)
nFire <- sum(dp$dataQL[VisitID=="BL"]$attendDem_fire)
nParamedic <- sum(dp$dataQL[VisitID=="BL"]$attendDem_emt)
nPhysician <- sum(dp$dataQL[VisitID=="BL"]$attendDem_physician)
nNurse <- sum(dp$dataQL[VisitID=="BL"]$attendDem_nurse)
nArnppa <- sum(dp$dataQL[VisitID=="BL"]$attendDem_arnppa)
fieldVector <- data.table(nHCW,nFR,nPolice,nFire,nParamedic,nPhysician,nNurse,nArnppa)
fieldVector

###########################dp$dataQL[VisitID=="BL"]$attendDem_HCW
# III. Pull out the STNI data to use, along with some demographics
###########################

# 1) What variables do we want to preserve?

# Demographic and basic ID variables:
var2keep=c("PtID","VisitID","age","gender")

# The STNI itself:
dp$dictionaryQL[Base=="STNI"]$VarID
var2keep=c(var2keep,dp$dictionaryQL[Base=="STNI"]$VarID)

# Let's remind ourselves why there's stni10 and stni10a (and same for 11):
dp$dictionaryQL[VarID=="stni10"]
dp$dictionaryQL[VarID=="stni10a"]
  # The answer is in the FieldLabel for stni10a: 
dp$dictionaryQL[VarID=="stni10a"]$FieldLabel
  # "Adjusted version of stni10 so monotonic"
  # Ie, if you look at the order of the answer choices:
dp$dictionaryQL[VarID=="stni10"]$answerChoices
  # ...they were out of order from the way it would make sense to
  # analyze them, ie, "never woken up sweaty" was the last=4 instead of first=0
  # So, stni10a is the same question but with the answer choices
  # rearranged so that never woken up sweaty is coded as 0
  # (stni11 vs 11a is the same)

# Make the actual tight data set:
data=dp$dataQL[,..var2keep] # note the ".." notation, which is very specific but handy; 
  # see this source for its function: https://stackoverflow.com/questions/12391950/select-assign-to-data-table-when-variable-names-are-stored-in-a-character-vect
dictionary=dp$dictionaryQL[VarID%in%var2keep]

# Pull the demographic variables forward now, because otherwise I forget all the time:
temp=data[VisitID=="BL",.(PtID,age,gender)]
data[,age:=NULL]
data[,gender:=NULL]
data=merge(data,temp,by="PtID",all.x=TRUE,all.y=FALSE)

# Drop any visits without a stniTotal, as we only want complete responses for this purpose:
data=data[!is.na(stniTotal)]
  # CONSIDER: do you want to go back and keep folks with NA for the bed partner dependent questions?

# How many responses does this leave?
dim(data) # 950 respodnses
length(unique(data$PtID)) # ...from 571 individual respondents 



#Write csv file for stni items 
write.csv(na.omit(data.table(stni1=dp$dataQL[VisitID=="BL"]$stni1,
           stni2=dp$dataQL[VisitID=="BL"]$stni2,
           stni3=dp$dataQL[VisitID=="BL"]$stni3,
           stni4=dp$dataQL[VisitID=="BL"]$stni4,
           stni5=dp$dataQL[VisitID=="BL"]$stni5,
           stni6=dp$dataQL[VisitID=="BL"]$stni6,
           stni7=dp$dataQL[VisitID=="BL"]$stni7,
           stni8=dp$dataQL[VisitID=="BL"]$stni8,
           stni9=dp$dataQL[VisitID=="BL"]$stni9,
           stni10=dp$dataQL[VisitID=="BL"]$stni10a,
           stni11=dp$dataQL[VisitID=="BL"]$stni11a)))
#Write csv file for shorter STNI
write.csv(na.omit(data.table(stni1=dp$dataQL[VisitID=="BL"]$stni1,
                             stni2=dp$dataQL[VisitID=="BL"]$stni2,
                             stni3=dp$dataQL[VisitID=="BL"]$stni3,
                             stni4=dp$dataQL[VisitID=="BL"]$stni4,
                             stni5=dp$dataQL[VisitID=="BL"]$stni5,
                             stni6=dp$dataQL[VisitID=="BL"]$stni6,
                             stni7=dp$dataQL[VisitID=="BL"]$stni7,
                             stni8=dp$dataQL[VisitID=="BL"]$stni8,
                             stni9=dp$dataQL[VisitID=="BL"]$stni9,
                             stni10=dp$dataQL[VisitID=="BL"]$stni10a,
                             stni11=dp$dataQL[VisitID=="BL"]$stni11a)))
#CSV file for STNI Short
write.csv(na.omit(data.table(stni1=dp$dataQL[VisitID=="BL"]$stni1,
                             stni2=dp$dataQL[VisitID=="BL"]$stni2,
                             stni3=dp$dataQL[VisitID=="BL"]$stni3,
                          #Possible add on for partner questions
                             #stni8=dp$dataQL[VisitID=="BL"]$stni8,
                             #stni9=dp$dataQL[VisitID=="BL"]$stni9,

                             stni11=dp$dataQL[VisitID=="BL"]$stni11a)))
#TEST
#(data.table(na.omit(
#            stni1=dp$dataQL[VisitID=="BL"]$stni1,
#            stni2=dp$dataQL[VisitID=="BL"]$stni2,
#            stni3=dp$dataQL[VisitID=="BL"]$stni3,
#            stni4=dp$dataQL[VisitID=="BL"]$stni4,
#            stni5=dp$dataQL[VisitID=="BL"]$stni5,
#            stni6=dp$dataQL[VisitID=="BL"]$stni6,
#            stni7=dp$dataQL[VisitID=="BL"]$stni7,
#            stni10=dp$dataQL[VisitID=="BL"]$stni10a,
#            stni11=dp$dataQL[VisitID=="BL"]$stni11a))&is.na(dp$dataQL$stni8))
            
#STNI and PCL datatable
View(data.table(na.omit(
  (stniTotal=dp$dataQL[VisitID=="BL"]$stniTotal) &
  (pclTotal=dp$dataQL[VisitID=="BL"]$pcl5Total))))

(stniTotal=dp$dataQL[VisitID=="BL"]$stniTotal) &
  (pclTotal=dp$dataQL[VisitID=="BL"]$pcl5Total)
#Wow did this actually work?
plot(na.omit(dp$dataQL[VisitID=="BL", .(stni9total, pcl5Total)]))
ggplot(dp$dataQL[VisitID=="BL"], aes(x=stni9total, y=pcl5Total))+geom_point()

dp$dataQL$pcl5Total[1]
dp$dataQL$stni9total[1]
data.table(na.omit(dp$dataQL$stni9total))
data.table(na.omit(dp$dataQL$pcl5Total))
dp$dataQL$trelative
(data.table(dp$dataQL[VisitID=="OO3mo"]$stni9total, dp$dataQL[VisitID=="BL"]$stni9total))
View(dp$dataQL)

#PTSD Diagnosis
#na.omit((dp$dataQL$pcl5i1>=2 & 
#    dp$dataQL$pcl5i2>=2 |
#    dp$dataQL$pcl5i3>=2 |
#    dp$dataQL$pcl5i4>=2 |
#    dp$dataQL$pcl5i5>=2) &
#      (dp$dataQL$pcl5i6 |
#       dp$dataQL$pcl5i7) &
#          (if sum(
#            dp$dataQL$pcl5i8>=2 |
#            dp$dataQL$pcl5i9>=2 |
#            dp$dataQL$pcl5i10>=2| 
#            dp$dataQL$pcl5i11>=2| 
#            dp$dataQL$pcl5i12>=2| 
#            dp$dataQL$pcl5i13>=2|
#            dp$dataQL$pcl5i14>=2)>=2))
    
#)

na.omit(sum(dp$dataQL$pcl5i8>2 |
  dp$dataQL$pcl5i9>2))

dp$dataQL$pcl5i8[1]


for(i in 1:100){
    if(sum(
        sum(dp$dataQL$pcl5i8[i]>=2)))
        #+
        #sum(dp$dataQL$pcl5i9[i]>=2) +
        #sum(dp$dataQL$pcl5i10[i]>=2)+ 
        #sum(dp$dataQL$pcl5i11[i]>=2)+ 
        #sum(dp$dataQL$pcl5i12[i]>=2)+ 
        #sum(dp$dataQL$pcl5i13[i]>=2)+
        #sum(dp$dataQL$pcl5i14[i]>=2))>=2) 
    {
  print("TRUE")
}
    else{
      print("FALSE")
    }
}
  
for(i in 1:100){
  if(is.na(dp$dataQL$pcl5i8[i]))
  {
    cat(i, "NA", sep = "")
  }
  else{if(dp$dataQL$pcl5i8[i]>=2)
    #+
    #sum(dp$dataQL$pcl5i9[i]>=2) +
    #sum(dp$dataQL$pcl5i10[i]>=2)+ 
    #sum(dp$dataQL$pcl5i11[i]>=2)+ 
    #sum(dp$dataQL$pcl5i12[i]>=2)+ 
    #sum(dp$dataQL$pcl5i13[i]>=2)+
    #sum(dp$dataQL$pcl5i14[i]>=2))>=2) 
  {
    cat(i,"TRUE", sep="")
  }
  else{
    cat(i, "FALSE", sep="")
  }
  
  }
}

#data.table(,
#           for(i in 1:10){
#             if(is.na(dp$dataQL$pcl5i8[i]))
#             {
#               ("NA")
#             }
#           else{if(
#                 dp$dataQL$pcl5i8[i]>=2)+
#             (dp$dataQL$pcl5i9[i]>=2) +
#             (dp$dataQL$pcl5i10[i]>=2)+ 
#             (dp$dataQL$pcl5i11[i]>=2)+ 
#             (dp$dataQL$pcl5i12[i]>=2)+ 
#             (dp$dataQL$pcl5i13[i]>=2)+
#             (dp$dataQL$pcl5i14[i]>=2))>=2) 
#           {
#             "TRUE"
#           }
#             else{
#             "FALSE"
#             }
#             
#           }
#           }
#)

#for(i in 1:10){
#  data.table[, paste0()]
#}

```

```{r echo=TRUE, message=TRUE, warning=TRUE}

#This code takes the data from dp$dataQL and looks at the PCL5 data, and determines if the participant meets criteria for provisional PTSD diagnosis according to this statement: A provisional PTSD diagnosis can be made by treating each item rated as 2 = "Moderately" or higher as a symptom endorsed, then following the DSM-5 diagnostic rule which requires at least: 1 B item (questions 1-5), 1 C item (questions 6-7), 2 D items (questions 8-14), 2 E items (questions 15-20).

library(data.table)
y<-data.table()

for (i in 1:3360)
{
 tmp<- if(anyNA(c(
   dp$dataQL$pcl5i1[i],
   dp$dataQL$pcl5i2[i],
   dp$dataQL$pcl5i3[i],
   dp$dataQL$pcl5i4[i],
   dp$dataQL$pcl5i5[i],
   dp$dataQL$pcl5i6[i],
   dp$dataQL$pcl5i7[i],
   dp$dataQL$pcl5i8[i],
   dp$dataQL$pcl5i9[i],
   dp$dataQL$pcl5i10[i],
   dp$dataQL$pcl5i11[i],
   dp$dataQL$pcl5i12[i],
   dp$dataQL$pcl5i13[i],
   dp$dataQL$pcl5i14[i],
   dp$dataQL$pcl5i15[i],
   dp$dataQL$pcl5i16[i],
   dp$dataQL$pcl5i17[i],
   dp$dataQL$pcl5i18[i],
   dp$dataQL$pcl5i19[i],
   dp$dataQL$pcl5i20[i])))
  {
    (NA)
  }
  else{
    if (((((sum(
    sum(dp$dataQL$pcl5i1[i]>=2)+
    sum(dp$dataQL$pcl5i2[i]>=2)+
    sum(dp$dataQL$pcl5i3[i]>=2)+
    sum(dp$dataQL$pcl5i4[i]>=2)+
    sum(dp$dataQL$pcl5i5[i]>=2)))>=1)&
  ((sum(
    sum(dp$dataQL$pcl5i6[i]>=2)+  
    sum(dp$dataQL$pcl5i7[i]>=2)))>=1))&
  ((sum(
    sum(dp$dataQL$pcl5i8[i]>=2)+
    sum(dp$dataQL$pcl5i9[i]>=2)+
    sum(dp$dataQL$pcl5i10[i]>=2)+ 
    sum(dp$dataQL$pcl5i11[i]>=2)+ 
    sum(dp$dataQL$pcl5i12[i]>=2)+ 
    sum(dp$dataQL$pcl5i13[i]>=2)+
    sum(dp$dataQL$pcl5i14[i]>=2)))>=2))&
  ((sum(
    sum(dp$dataQL$pcl5i15[i]>=2)+
    sum(dp$dataQL$pcl5i16[i]>=2)+
    sum(dp$dataQL$pcl5i17[i]>=2)+ 
    sum(dp$dataQL$pcl5i18[i]>=2)+ 
    sum(dp$dataQL$pcl5i19[i]>=2)+ 
    sum(dp$dataQL$pcl5i20[i]>=2)))>=2))
    {
     (TRUE)
    }
      else{
        (FALSE)
          }
       }   
   
 y<- rbind(y, tmp)
}

y[, ':=' (PtID = dp$dataQL$PtID,
          VisitID = dp$dataQL$VisitID,
          trel = dp$dataQL$trelative,
          int1 = between(dp$dataQL$trelative, 80, 100),
          int2 = between(dp$dataQL$trelative, 160, 200),
          stniTotal=dp$dataQL$stniTotal,
          stni9total=dp$dataQL$stni9total,
          isiTotal= dp$dataQL$isi_total,
          pcl5Total = dp$dataQL$pcl5total,
          pclB = dp$dataQL$pcl5clusterB,
          pclC = dp$dataQL$pcl5clusterC,
          pclD = dp$dataQL$pcl5clusterD,
          pclE = dp$dataQL$pcl5clusterE,
          ceaptwTotal = dp$dataQL$ceaPTW_total,
          phq9Total = dp$dataQL$phq9total,
          gad7Total = dp$dataQL$gad7total,
          stnimini = (dp$dataQL$stni1 + dp$dataQL$stni2 + dp$dataQL$stni3 + dp$dataQL$stni4 + dp$dataQL$stni5 + dp$dataQL$stni6 + dp$dataQL$stni11a))
          ]#,
          #pcl5i1 = dp$dataQL$pcl5i1,
          #pcl5i2 = dp$dataQL$pcl5i2,
          #pcl5i3 = dp$dataQL$pcl5i3,
          #pcl5i4 = dp$dataQL$pcl5i4,
          #pcl5i5 = dp$dataQL$pcl5i5,
          #pcl5i6 = dp$dataQL$pcl5i6,
          #pcl5i7 = dp$dataQL$pcl5i7,
          #pcl5i8 = dp$dataQL$pcl5i8,
          #pcl5i9 = dp$dataQL$pcl5i9,
          #pcl5i10 = dp$dataQL$pcl5i10,
          #pcl5i11 = dp$dataQL$pcl5i11,
          #pcl5i12 = dp$dataQL$pcl5i12,
          #pcl5i13 = dp$dataQL$pcl5i13,
          #pcl5i14 = dp$dataQL$pcl5i14,
          #pcl5i15 = dp$dataQL$pcl5i15,
          #pcl5i16 = dp$dataQL$pcl5i16,
          #pcl5i17 = dp$dataQL$pcl5i17,
          #pcl5i18 = dp$dataQL$pcl5i18,
          #pcl5i19 = dp$dataQL$pcl5i19,
          #pcl5i20 = dp$dataQL$pcl5i20)]

     #int1 = between(y$trel, 80, 100)
     #int2 = between(y$trel, 160, 200)

  #y<- rbind(y, int1)


#Plot for BL pcl Scores
#ggplot(y[VisitID=="BL"], aes(x=(pcl5Total)))+geom_histogram()
#plot for BL PTSD ratio
#ggplot(na.omit(y[VisitID=="BL"]), aes(x=x))+geom_bar()
#y[,':='(pcl5i1 = data.table(dp$dataQL$pcl5i1))]
library(ggplot2)
#ggplot(y[VisitID=="BL"], aes(x=pcl5Total))+geom_histogram(bins=79)
#ggplot(y, aes(x=pcl5Total))+geom_histogram(bins=79)

#ggplot(y, aes(x=phq9Total))+geom_histogram(bins=28)

ggplot(y, aes(x=gad7Total))+geom_histogram(bins=22)

ggplot(y, aes(x=ceaptwTotal))+geom_histogram(bins=37)

ggplot(y, aes(x=stniTotal))+geom_histogram(bins=35)
# revised df for y
int <- y[int1=="TRUE"|int2=="TRUE"][VisitID=="OO3mo"]

int[,':=' (timep = as.character(as.integer(int$int2)))]


ggplot(data= int[int1==TRUE], mapping = aes(x=stniTotal, y=pcl5Total))+geom_point()
ggplot(data= int[int2==TRUE], mapping = aes(x=stniTotal, y=pcl5Total))+geom_point()


ggplot(data= int[int1==TRUE], mapping = aes(x=stniTotal, y=pcl5Total))+geom_point()

#PCL5 and STNI correlation
#ggplot(data = int)+geom_point(int[int1==TRUE], mapping = aes(x=stniTotal, y=pcl5Total), color="blue", alpha=.3) + geom_point(int[int2==TRUE], mapping = aes(x=stniTotal, y=pcl5Total), color="red", alpha=.3)

#ggplot(data=int)+geom_point(int, mappping = aes(x=stniTotal, y=pcl5Total), color = int$timep)

#ggplot(data=int, aes(x=stniTotal, y=pcl5Total, color=int$timep))+geom_point(alpha=0.6)
#THIS ONE ACTUALLY WORKS WITH LABEL, STNI + PCL
ggplot(data=int, aes(x=stniTotal, y=pcl5Total, color = factor(int$timep, labels = c("3mo","6mo"))))+geom_point(alpha=0.6, position="jitter")+labs(color="Time frame")
#STNI AND ISI
ggplot(data=int, aes(x=stniTotal, y=isiTotal, color = factor(int$timep, labels = c("3mo","6mo"))))+geom_point(alpha=0.6, position="jitter")+labs(color="Time frame")


#for ISI and STNI correlation
#ggplot(data = int)+geom_point(int[int1==TRUE], mapping = aes(x=stniTotal, y=isitotal), color="blue", alpha=.3) + geom_point(int[int2==TRUE], mapping = aes(x=stniTotal, y=isitotal), color="red",alpha = .3, labels="int2")+labs(color="int2")


nint2<-int[int2==TRUE]
nint1<-int[int1==TRUE]

#cor(nint1$stniTotal, nint1$pcl5Total, use="complete.obs")
#length(nint2$stniTotal) <- length(nint1$stniTotal)
#length(nint2$pcl5Total) <- length(nint1$pcl5Total)

#ggplot(nint1, aes(x=stniTotal))+geom_histogram()
#given cutoff of 33 for PCL, proportionally equivalent to a score of 14 on the stni9Total, or 13 if cutoff is 31

ggplot(dp$dataQL[VisitID=="BL"], aes(x=pclTotal)) + geom_histogram(bins=34)
#data.table(dp$dataQL$pcl5i1)
```

```{r}

#this is to try and compare results from 3mo and 6mo interal

#between(y$trel, 80, 100)
#between(y$trel, 160, 200)

# =(y[int2=="TRUE"][VisitID=="OO3mo"])
#mo1 =(y[int1=="TRUE"][VisitID=="OO3mo"])

int <- y[int1=="TRUE"|int2=="TRUE"][VisitID=="OO3mo"]

dif <- y[int1=="TRUE"|int2=="TRUE"][VisitID=="OO3mo"]
#stnimo1 = mo1$stniTotal
#pclmo1 = mo1$pcl5Total
#plot(stnimo1,pclmo1)

#stnimo2= mo2$stniTotal
#pclmo2=mo2$pcl5Total
#plot(stnimo2, pclmo2)

#dupe<-as.numeric(factor(int$PtID))
#int[,dupe:=NULL]
int[,':='(dupe=as.numeric(factor(int$PtID)))]
anyDuplicated(as.numeric(factor(int$PtID)))
  rem <-c(2, 7, 9, 10, 13, 14, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 34, 35, 36, 38, 39, 40, 41, 44, 46, 47, 48, 49, 52, 55, 59, 63, 64, 66, 69, 70, 76, 78,79,80,81,83,84,85,88,91,92,93,95,96,97,98,100,101,103,104,107,108,109,110,111,113,115,116,117,118,119,120,122,124,125,126,128,129,130,131,132,133,134,136,137,138,139,140,141,142,143,144,145,146,148,151,153,154,155,156,158,161,163,167,168,169,170,171,178,182,183,185,186,187,188,189,191,192,193,194,195,197,198,199,203,205,207,209,216,223,225,230,231,232,233,234,235,236,237,238,239,240,244,245,250,252,253,254,255,257,258,259,260,263,266)
#for(rem in int$dupe)

#int[dupe]  

#for (i in 1:390){
#  idk1<-if(any(int$dupe[i]==rem)){
#    print(i)
#  }
#}
#int <- rbind(int,idk1)  
#I think this is the one that works to say which rows are not paired
ppl2 <- character()
for (i in 1:390){
  ppl<- any(int$dupe[i]==rem)
  ppl2<-c(ppl2, ppl)
  }
ppl2 <-as.logical(ppl2)
#int[,':='(paired=NULL)]
int[,':='(paired = !ppl2)] 

(int[paired==TRUE]$stniTotal)
#These diffs aren't actually correct, need to find a way to find diff of every two paired points but without any non-paired points. Nrow should be half of int

abs(diff((int[paired==TRUE]$stniTotal)))


#diffs in STNI mini
#MAY BE AN ISSUE SINCE ORDER OF INT1 and INT2 MAY BE OFF, MAY MESS UP NAs
#ACTUALLY NO I DONT THINK SO, IT SKIPS EVERY OTHER ONE BECAUSE THE DIFF FUNCTION COMPARES EVERY SUBSEQUENT SET OF TWO, WHICH ISN'T IMPORTANT FOR THIS SINCE WE'RE ONLY LOOKING AT PAIRED ITEMS, DON'T NEED TO LOOK AT DIFFERENCES BETWEEN NON-PAIRED ITEMS
stnimdiff <- diff((int[paired==TRUE]$stnimini))
stnimdiff <- stnimdiff[c(TRUE,FALSE)]
#diffs in STNI
stnidiff<-diff((int[paired==TRUE]$stni9total))

stnidiff<- stnidiff[c(TRUE, FALSE)]
#diffs in PCL5
pcldiff<-diff(int[paired==TRUE]$pcl5Total)
pcldiff<- pcldiff[c(TRUE, FALSE)]

#diffs in ISI
isidiff<-diff((int[paired==TRUE]$isiTotal))
isidiff<-isidiff[c(TRUE,FALSE)]
#diffs in PCL5E
pclediff <- diff(int[paired==TRUE]$pclE)
pclediff<- pclediff[c(TRUE,FALSE)]
#diffs in PCL5B
pclbdiff <- diff(int[paired==TRUE]$pclB)
pclbdiff<- pclbdiff[c(TRUE,FALSE)]
#diffs in PCL5C
pclcdiff <- diff(int[paired==TRUE]$pclC)
pclcdiff<- pclcdiff[c(TRUE,FALSE)]
#diffs in PCL5D
pclddiff <- diff(int[paired==TRUE]$pclD)
pclddiff<- pclddiff[c(TRUE,FALSE)]
#diffs in gad7
gad7diff<-diff(int[paired==TRUE]$gad7Total)
gad7diff<-gad7diff[c(TRUE,FALSE)]
#diffs in phq9
phq9diff <- diff(int[paired==TRUE]$phq9Total)
phq9diff <- phq9diff[c(TRUE,FALSE)]
#diffs in occupational exposure
ceaptwdiff<- diff(int[paired==TRUE]$ceaptwTotal)
ceaptwdiff<- ceaptwdiff[c(TRUE, FALSE)]
diffs = data.table(stnidiff, pcldiff, pclbdiff, pclcdiff, pclddiff, pclediff, isidiff, gad7diff, phq9diff, ceaptwdiff)
#diffs = data.table(stnidiff<-abs(diff((int[paired==TRUE]$stniTotal))),pcldiff<-abs(diff((int[paired==TRUE]$pcl5Total))))
#diffs[,dupe:=(int[paired==TRUE]$dupe)]
ggplot(diffs, aes(x=stnidiff, y=pcldiff))+geom_point()
ggplot(diffs, aes(x=stnidiff, y=isidiff))+geom_point()
ggplot(diffs, aes(x=stnidiff, y=gad7diff))+geom_point()
ggplot(diffs, aes(x=stnidiff, y=phq9diff))+geom_point()
ggplot(diffs, aes(x=stnidiff, y=ceaptwdiff))+geom_point()
#ggplot(diffs, aes(x=stnidiff, y=pclediff))+geom_point()
#STNI mini diff corr with other sclaes
cor.test(stnidiff, pcldiff, use="complete.obs")
cor.test(stnidiff, isidiff, use="complete.obs")
cor.test(stnidiff, gad7diff, use="complete.obs")
cor.test(stnidiff, phq9diff, use="complete.obs")
cor.test(stnidiff, ceaptwdiff, use="complete.obs")
#Stni diff corr with other scales
cor.test(stnidiff, pcldiff, use="complete.obs")
cor.test(stnidiff, isidiff, use="complete.obs")
cor.test(stnidiff, gad7diff, use="complete.obs")
cor.test(stnidiff, phq9diff, use="complete.obs")
cor.test(stnidiff, ceaptwdiff, use="complete.obs")
#Pretty much the same

#Some cors with age
cor.test(dp$dataQL$age, dp$dataQL$stni9total, use="complete.obs")
#cor.test(dp$dataQL$age, dp$dataQL$pcl5Total, use="complete.obs")
cor.test(dp$dataQL$age, dp$dataQL$gad7total, use="complete.obs")
cor.test(dp$dataQL$age, dp$dataQL$phq9total, use="complete.obs")


#STNI diff most correlated with PCL B, interestingly

library(pROC)

# Maps STNI positive rate to PCL5 positive rate

#int[, ':='(diag = as.numeric(int$x)),by=1:nrow(int)]
int[,diag:=as.numeric(x),by=1:nrow(int)]

pROC<- roc(as.numeric(int$stni9total>13), int$diag, smoothed=TRUE, ci=TRUE, ci.alpha = 0.9, stratified = FALSE, plot=TRUE, auc.polygon = TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)

#int[, ':='(diag = as.numeric(y$x)),by=1:nrow(int)]

#Cor of STNI with PCLB, quite strong at .73, less strong than stni as a whole though
cor.test(y[VisitID=="BL"]$pclB, y[VisitID=="BL"]$stni9total, use="complete.obs")
#More Cors
cor.test(y[VisitID=="BL"]$stni9total, y[VisitID=="BL"]$pcl5Total, use="complete.obs")
cor.test(y[VisitID=="BL"]$stni9total, y[VisitID=="BL"]$isiTotal, use="complete.obs")

int[,diag:=NULL]

class(int$diag)
View(int)
ggplot(int, aes(x=pcl5Total, y=x))+geom_point()
roc<- ci.se(pROC)
plot(roc, type = "shape")
```

```{r}

#Going to try another set of ROC curves here, since the other ones are kinda iffy

#library(pROC)
#install.packages("verification")
#library(verification)
#roc.plot(y$stniTotal, y$pcl5Total)
#roc()

library(ROCR)

 prediction(na.omit(y[VisitID=="BL"]$stni9total), na.omit(y[VisitID=="BL"]$pcl5Total))

```


```{r}
#This is to try and find ROC curve for STNI and PCL
#install.packages("pROC")
library(pROC)

# Maps STNI positive rate to PCL5 positive rate

#int[, ':='(diag = as.numeric(int$x)),by=1:nrow(int)]
int[,diag:=as.numeric(x),by=1:nrow(int)]
#This one takes positive STNI ruling and compares to postiive PCL5 diagnosis 
#pROC<- roc(as.numeric(int$stniTotal>13), int$diag, smoothed=TRUE, ci=TRUE, ci.alpha = 0.9, stratified = FALSE, plot=TRUE, auc.polygon = TRUE, max.auc.polygon=TRUE, grid=TRUE,
#            print.auc=TRUE, show.thres=TRUE)

#This one works??? Higher AUC than PSQI-A to detect PTSD (though PSQI-A used CAPS, STNI used PCL)
pROC1<- roc(int$diag, int$stni9total, smoothed=TRUE, ci=TRUE, stratified = FALSE, plot=TRUE, auc.polygon = TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
#STNI score of 8 or greater yields highest sensitivity to specitivity ratio 
pROC2<- roc(int$diag, as.numeric(int$stniTotal>8), smoothed=TRUE, ci=TRUE, stratified = FALSE, plot=TRUE, auc.polygon = TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE, ci.se=TRUE, ci.sp=TRUE)
#STNI To ISI, quite good at predicting insomnia with a cutoff of 15
pROC3<- roc(int$isiTotal>15, as.numeric(int$stni9total), smoothed=TRUE, ci=TRUE, stratified = FALSE, plot=TRUE, auc.polygon = TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE, ci.se=TRUE, ci.sp=TRUE)
#This one works too??
pROC4<- multiclass.roc(int$diag, int$stni9total,plot=TRUE, auc.polygon = TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
#without repeats (DOUBLE CHECK PLEASE!!)**
ROC<- roc(int[int1==TRUE]$diag, int[int1==TRUE]$stni9total, smoothed=TRUE, ci=TRUE, stratified = FALSE, plot=TRUE, auc.polygon = TRUE, max.auc.polygon=TRUE, grid=TRUE, print.auc=TRUE, show.thres=TRUE)

ROC<- roc(int[int1==TRUE]$diag, int[int1==TRUE]$stni9total, smoothed=TRUE, ci=TRUE, stratified = FALSE, plot=TRUE, auc.polygon = TRUE,
          max.auc.polygon=TRUE, grid=TRUE, print.auc=TRUE, show.thres=TRUE)

#Baseline
ROC<- roc(as.numeric(y[VisitID=="BL"]$x), y[VisitID=="BL"]$stni9total, smoothed=TRUE, ci=TRUE, stratified = FALSE, plot=TRUE, auc.polygon = TRUE, max.auc.polygon=TRUE, grid=TRUE, print.auc=TRUE, show.thres=TRUE)

ci.thresholds(as.numeric(y[VisitID=="BL"]$x), y[VisitID=="BL"]$stni9total,tresholds=c(9))
#Check sensitivity and specificity 
ci.thresholds(int[int1==TRUE]$diag, int[int1==TRUE]$stni9total, thresholds=c(9))
#Cutoff of 9 on the STNI seems to give the greatest sensitivity/specificity ratio
ci.se(int[int1==TRUE]$diag, int[int1==TRUE]$stni9total)
#I don't know enough about ROC curves to be sure but it seems to make sense?
```

```{r}

#TEST RETEST VALIDITY
#Trying to get a set of paired tests of each unique participant, however running into issues where one of the pairs is NA
#install.packages("knitr")

#write.csv(int[paired==TRUE][int1==TRUE]$stniTotal)

#write.csv(int[paired==TRUE][int2==TRUE]$stniTotal)

#I guess can just do it manually??
#Used CSV to get row numbers

#remove 28, 39, 45, 48, 49, 57, 82, 109, 112, 21, 28, 44, 49, 51, 119
sort(c(28, 39, 45, 48, 49, 57, 82, 109, 112, 21, 28, 44, 49, 51, 119))

trt1<-int[paired==TRUE][int2==TRUE]$stni9total
  trt1<- trt1[-c(28, 39, 45, 48, 49, 57, 82, 109, 112, 21, 28, 44, 49, 51, 119)]
trt2<-int[paired==TRUE][int1==TRUE]$stni9total
  trt2<- trt2[-c(28, 39, 45, 48, 49, 57, 82, 109, 112, 21, 28, 44, 49, 51, 119)]

  
#trtBL <- dp$dataQL[VisitID=="BL"]$stniTotal
# trtBL2 <- data.table()
# y1=i
# y2=dp$dataQL[VisitID=="BL"][PtID==paste("H", i, sep="")]$stni1
#for (i in 1:827)
#{
#  
#  trtBL2[,':=' (y1= y1,
#               y2= y2)
#        ]#

#}
# trtBL3 <- data.table()
# for (i in 1:827)
#{
#  trtBL3[, ":="(y1 = paste("H", i, sep=""))]
# }
# 
# trtBL = data.table()
## for (i in 1:827)
 #{
#   op <-  paste("H", i, sep="")
#   ops <- dp$dataQL[VisitID=="BL"]$stni9total
#   trtBL <- rbind(trtBL, op)
#   #trtBL <- rbind (trtBL, ops)
# }
# for (i in 1:827){
# trtBL[, stniTotal := as.vector(dp$dataQL[VisitID=="BL"[PtID=="/""paste("H", i, sep="")"]$stni9total)]
#}
##dp$dataQL[VisitID=="BL"][PtID=="H25"]

  #Uses ID numbers to pull stni scores
  trtr <- data.frame()
  for (i in 1:827)
 {
   trtrt <- dp$dataQL[PtID==paste("H",i,sep="")][VisitID=="BL"]$stni9total
   trtr <- rbind(trtr, trtrt)
 }
setDT(trtr)
#Sets ID numbers in data frame
trtrt <- data.table()
  for (i in 1:827)
  {
    asd <- paste("H", i, sep="")
    trtrt <- rbind(trtrt, asd)
  }
#Combines the two above into a single data table
trtBL <- data.table(trtrt, trtr)
colnames(trtBL) <- c("ID", "stni9total")

#Adds stni scores from INT 1 to data table
trtint1 <- data.table()
for (i in 1:827)
{
  asdf <-  y[PtID==paste("H",i,sep="")][int1 == TRUE]$stni9total
  trtint1 <- rbind(trtint1, asdf)
}
#Adds IDs from INT1 to data frame
trtint2 <- data.table()
for (i in 1:827)
{
  asdf <-  y[PtID==paste("H",i,sep="")][int1 == TRUE]$PtID
  trtint2 <- rbind(trtint2, asdf)
}

trtBL2 <- data.table()
for (i in 1:235)
{
aw<- trtBL[ID==trtint2$x[i]]
trtBL2 <- rbind(trtBL2, aw)
}

trtBLINT<-data.table(trtBL2, trtint1) #double check
colnames(trtBLINT)<- c("ID", "BL", "Int1")
trtBLINT <- na.omit(trtBLINT)
#This should give us our test retest validity
cor.test(trt1, trt2)
cor.test(trtBLINT$BL, trtBLINT$Int1) #Double check

```

```{r}
#Trying out Convergent and Discriminate Validity 
#install.packages("psy")
library(psy)
#Following is for CFA
#install.packages("foreign", dependencies = TRUE)
#install.packages("lavaan", dependencies = TRUE)
library(foreign)
library(lavaan)
 

```
```{r}
bl <- data.table()
bl[, ':=' (PtID = dp$dataQL[VisitID=="BL"]$PtID,
          #VisitID = dp$dataQL$VisitID,
          #trel = dp$dataQL$trelative,
          #int1 = between(dp$dataQL$trelative, 80, 100),
          #int2 = between(dp$dataQL$trelative, 160, 200),
          stni9total=dp$dataQL[VisitID=="BL"]$stni9total,
          isiTotal= dp$dataQL[VisitID=="BL"]$isi_total,
          pcl5Total = dp$dataQL[VisitID=="BL"]$pcl5total,
          pclB = dp$dataQL[VisitID=="BL"]$pcl5clusterB,
          pclC = dp$dataQL[VisitID=="BL"]$pcl5clusterC,
          pclD = dp$dataQL[VisitID=="BL"]$pcl5clusterD,
          pclE = dp$dataQL[VisitID=="BL"]$pcl5clusterE,
          ceaptwTotal = dp$dataQL[VisitID=="BL"]$ceaPTW_total,
          phq9Total = dp$dataQL[VisitID=="BL"]$phq9total,
          gad7Total = dp$dataQL[VisitID=="BL"]$gad7total)
          #stnimini = (dp$dataQL$stni1 + dp$dataQL$stni2 + dp$dataQL$stni3 + dp$dataQL$stni4 + dp$dataQL$stni5 + dp$dataQL$stni6 + dp$dataQL$stni11a))
          ]#,
          #pcl5i1 = dp$dataQL$pcl5i1,
          #pcl5i2 = dp$dataQL$pcl5i2,
          #pcl5i3 = dp$dataQL$pcl5i3,
          #pcl5i4 = dp$dataQL$pcl5i4,
          #pcl5i5 = dp$dataQL$pcl5i5,
          #pcl5i6 = dp$dataQL$pcl5i6,
          #pcl5i7 = dp$dataQL$pcl5i7,
          #pcl5i8 = dp$dataQL$pcl5i8,
          #pcl5i9 = dp$dataQL$pcl5i9,
          #pcl5i10 = dp$dataQL$pcl5i10,
          #pcl5i11 = dp$dataQL$pcl5i11,
          #pcl5i12 = dp$dataQL$pcl5i12,
          #pcl5i13 = dp$dataQL$pcl5i13,
          #pcl5i14 = dp$dataQL$pcl5i14,
          #pcl5i15 = dp$dataQL$pcl5i15,
          #pcl5i16 = dp$dataQL$pcl5i16,
          #pcl5i17 = dp$dataQL$pcl5i17,
          #pcl5i18 = dp$dataQL$pcl5i18,
          #pcl5i19 = dp$dataQL$pcl5i19,
          #pcl5i20 = dp$dataQL$pcl5i20)]

     #int1 = between(y$trel, 80, 100)
     #int2 = between(y$trel, 160, 200)

```


```{r}
#this is for calculating ROC curve of STNI graph (I guess)
#install.packages("ROCR")
#library(ROCR)


#int[, ':='(diag = as.numeric(y$x)),by=1:nrow(int)]


int[,diag:=NULL]

class(int$diag)
View(int)
ggplot(int, aes(x=pcl5Total, y=x))+geom_point()
roc<- ci.se(pROC)
plot(roc, type = "shape")
```

```{r}

#This is so I can figure out demographics for the STNI Results
dems <- data.table(dp$dataQL[VisitID=="BL"]$PtID, dp$dataQL[VisitID=="BL"]$stniTotal, dp$dataQL[VisitID=="BL"]$gender, dp$dataQL[VisitID=="BL"]$raceConcatenated, dp$dataQL[VisitID=="BL"]$ethnicityConcatenated)

colnames(dems)<-c("ID", "STNI", "Gender", "Race", "Ethnicity")

stnidems <- data.table(dems[is.na(dems$STNI)==FALSE]$ID, dems[is.na(dems$STNI)==FALSE]$STNI,dems[is.na(dems$STNI)==FALSE]$Gender, dems[is.na(dems$STNI)==FALSE]$Race, dems[is.na(dems$STNI)==FALSE]$Ethnicity)
colnames(stnidems)<-c("ID", "STNI", "Gender", "Race", "Ethnicity")

sum(na.omit(stnidems$Gender=="F"))
sum(na.omit(stnidems$Gender=="M"))
sum(na.omit(stnidems$Gender=="NB"))
sum(na.omit(stnidems$Gender=="O"))
length(na.omit(stnidems$Gender))
```
```{r}

cronbach.alpha(na.omit(data.table(dp$dataQL[VisitID=="BL"]$stni1, dp$dataQL[VisitID=="BL"]$stni2, dp$dataQL[VisitID=="BL"]$stni3, dp$dataQL[VisitID=="BL"]$stni4, dp$dataQL[VisitID=="BL"]$stni5, dp$dataQL[VisitID=="BL"]$stni6, dp$dataQL[VisitID=="BL"]$stni7, dp$dataQL[VisitID=="BL"]$stni8, dp$dataQL[VisitID=="BL"]$stni9, dp$dataQL[VisitID=="BL"]$stni10a, dp$dataQL[VisitID=="BL"]$stni11a)), CI=TRUE)

cronbach.alpha(na.omit(data.table(dp$dataQL[VisitID=="BL"]$stni1, dp$dataQL[VisitID=="BL"]$stni2, dp$dataQL[VisitID=="BL"]$stni3, dp$dataQL[VisitID=="BL"]$stni4, dp$dataQL[VisitID=="BL"]$stni5, dp$dataQL[VisitID=="BL"]$stni6, dp$dataQL[VisitID=="BL"]$stni7, dp$dataQL[VisitID=="BL"]$stni10a, dp$dataQL[VisitID=="BL"]$stni11a)), CI=TRUE)

```



#time PCL
na.omit(data.table(dp$dataQL[VisitID=="BL"]$PtID, dp$dataQL[VisitID=="BL"]$pcl5Total, dp$dataQL[VisitID=="OO2wk"]$pcl5Total))
